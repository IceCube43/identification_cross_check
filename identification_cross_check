# Section 6 (Identification Cross-Checks) — National Time-Series Essentials
# Outputs:
#   /mnt/data/section6_ts/table_S6_1_IV_lag12_2SPS.csv
#   /mnt/data/section6_ts/table_S6_2_placebo_time_permutation.csv
import os, warnings, numpy as np, pandas as pd
import statsmodels.api as sm, statsmodels.formula.api as smf
warnings.filterwarnings("ignore")

# ------------------------
# Paths & output directory
# ------------------------
OUTDIR = "section6_ts"; os.makedirs(OUTDIR, exist_ok=True)

AI_PATH_CANDIDATES   = ["AI_posting.csv"]
MACRO_PATH_CANDIDATES= ["fred_controls_us_monthly_2019_2025.csv"]

def _pick(paths):
    for p in paths:
        if os.path.exists(p): return p
    raise FileNotFoundError(f"None of these files were found: {paths}")

AI_PATH   = _pick(AI_PATH_CANDIDATES)
MACRO_PATH= _pick(MACRO_PATH_CANDIDATES)

# ------------------------
# Helpers
# ------------------------
def to_month(dt_like):
    s = pd.to_datetime(dt_like, errors="coerce")
    return s.dt.to_period("M").dt.to_timestamp()

def load_ai_us_monthly(ai_path=AI_PATH):
    # Expect columns: ['date','jobcountry','AI_share_postings'] (daily % share)
    usecols = None
    # robust loader that tolerates extra cols
    df = pd.read_csv(ai_path)
    low = {c:c.lower() for c in df.columns}
    date_col = [c for c in df.columns if "date" in low[c]][0]
    country_col = [c for c in df.columns if "jobcountry" in low[c]][0]
    ai_col = None
    for k in ["ai_share_postings","ai_share_pct","ai_share"]:
        cand = [c for c in df.columns if k in low[c]]
        if cand: ai_col = cand[0]; break
    if ai_col is None:
        raise KeyError("Could not find AI share column (e.g., 'AI_share_postings').")

    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    df = df[df[country_col].astype(str).str.upper().eq("US")].copy()
    df["month"] = df[date_col].dt.to_period("M").dt.to_timestamp()
    ai_m = (df.groupby("month", as_index=False)[ai_col]
              .mean()
              .rename(columns={"month":"date", ai_col:"ai_share_pct"}))
    # Winsorize 1% tails to stabilize the national TS
    lo, hi = ai_m["ai_share_pct"].quantile([0.01, 0.99])
    ai_m["ai_share_pct"] = ai_m["ai_share_pct"].clip(lo, hi)
    # Keep 2019+ per research window
    ai_m["date"] = to_month(ai_m["date"])
    ai_m = ai_m[ai_m["date"] >= pd.Timestamp("2019-01-01")]
    return ai_m

def load_macro(macro_path=MACRO_PATH):
    df = pd.read_csv(macro_path)
    # Column mapping (robust names)
    low = {c:c.lower() for c in df.columns}
    def pick(name_opts, req=True):
        for k in name_opts:
            for c in df.columns:
                if k in low[c]: return c
        if req: raise KeyError(f"Need a column like {name_opts}")
        return None

    date_col   = pick(["date"])
    infl_col   = pick(["inflation_yoy_pct","inflation_yoy","inflation"])
    ur_col     = pick(["unemployment_rate_pct","unemployment_rate","ur"])
    nairu_col  = pick(["nairu_pct","nairu"], req=False)
    ugap_col   = pick(["u_gap_pct_points","u_gap","unemployment_gap"], req=False)

    opt_controls = []
    for key in ["cpi_energy_yoy_pct","energy",
                "dxy_yoy_pct","dxy",
                "productivity_yoy_pct","productivity",
                "jolts_job_openings_rate_pct","jolts"]:
        c = pick([key], req=False)
        if c and c not in opt_controls: opt_controls.append(c)

    keep = [date_col, infl_col, ur_col] + ([nairu_col] if nairu_col else []) \
           + ([ugap_col] if ugap_col else []) + opt_controls
    df = df[keep].copy()
    df.rename(columns={date_col:"date", infl_col:"inflation_yoy_pct", ur_col:"unemployment_rate_pct"},
              inplace=True)
    if nairu_col: df.rename(columns={nairu_col:"nairu_pct"}, inplace=True)
    if ugap_col:  df.rename(columns={ugap_col:"u_gap_pct_points"}, inplace=True)
    # Normalize control names
    rename_map = {}
    for c in df.columns:
        cl = c.lower()
        if "cpi_energy" in cl or (cl=="energy"):
            rename_map[c] = "cpi_energy_yoy_pct"
        elif cl=="dxy" or "dxy_yoy" in cl:
            rename_map[c] = "dxy_yoy_pct"
        elif "productivity" in cl:
            rename_map[c] = "productivity_yoy_pct"
        elif "jolts" in cl:
            rename_map[c] = "jolts_job_openings_rate_pct"
    df.rename(columns=rename_map, inplace=True)

    df["date"] = to_month(df["date"])
    df = df[df["date"] >= pd.Timestamp("2019-01-01")]  # ensure 2019+ window
    # Optional micro-fix: drop the most problematic lockdown reporting month
    df = df[df["date"] != pd.Timestamp("2020-04-01")]
    return df

def add_infl_lags(df, lags=(1,12)):
    for L in lags:
        df[f"inflation_yoy_pct_lag{L}"] = df["inflation_yoy_pct"].shift(L)
    return df

# ------------------------
# Build national time series (no panel_us_monthly usage)
# ------------------------
ai = load_ai_us_monthly()
mc = load_macro()
df = pd.merge(mc, ai, on="date", how="left")

# Compute unemployment gap (prefer provided, else UR - NAIRU)
if "u_gap_pct_points" in df.columns and df["u_gap_pct_points"].notna().any():
    df["u_gap"] = df["u_gap_pct_points"]
else:
    if "nairu_pct" in df.columns and df["nairu_pct"].notna().any():
        df["u_gap"] = df["unemployment_rate_pct"] - df["nairu_pct"]
    else:
        # fallback: demeaned UR acts as 'gap' proxy (absorbs mean via centering)
        df["u_gap"] = df["unemployment_rate_pct"]

# Center variables for interaction
df["u_gap_c"]     = df["u_gap"] - df["u_gap"].mean(skipna=True)
df["ai_share_c"]  = df["ai_share_pct"] - df["ai_share_pct"].mean(skipna=True)
df["uxA"]         = df["u_gap_c"] * df["ai_share_c"]
# Lagged inflation for dynamics
df = add_infl_lags(df, lags=(1,12))

# Instrument: 12-month lag of AI share (centered)
df["ai_lag12"]    = df["ai_share_pct"].shift(12)
df["ai_lag12_c"]  = df["ai_lag12"] - df["ai_lag12"].mean(skipna=True)

# Drop rows with missing essentials
essentials = ["inflation_yoy_pct","u_gap_c","ai_share_c","uxA",
              "inflation_yoy_pct_lag1","inflation_yoy_pct_lag12","ai_lag12_c"]
df = df.dropna(subset=essentials).sort_values("date").copy()

# Collect optional controls that made it through
opt_controls = [c for c in ["cpi_energy_yoy_pct","dxy_yoy_pct",
                            "productivity_yoy_pct","jolts_job_openings_rate_pct"]
                if c in df.columns and df[c].notna().any()]

# ------------------------
# 1) First stage: ai_share_c ~ ai_lag12_c + controls   (HAC(12))
# ------------------------
rhs_fs = "ai_lag12_c" + ((" + " + " + ".join(opt_controls)) if opt_controls else "")
fs = smf.ols(f"ai_share_c ~ {rhs_fs}", data=df).fit(cov_type="HAC", cov_kwds={"maxlags":12})
t_ai = fs.tvalues.get("ai_lag12_c", np.nan)
F_first_stage = float(t_ai**2) if pd.notna(t_ai) else np.nan

# ------------------------
# 2) Second stage (2SPS, HAC): y ~ u_gap_c + (u_gap_c × ÂI) + lagged π + controls
# ------------------------
df["ai_hat"]    = fs.fittedvalues
df["ai_hat_c"]  = df["ai_hat"] - df["ai_hat"].mean()
df["uxA_hat"]   = df["u_gap_c"] * df["ai_hat_c"]

rhs_ss = "u_gap_c + uxA_hat + inflation_yoy_pct_lag1 + inflation_yoy_pct_lag12"
if opt_controls: rhs_ss += " + " + " + ".join(opt_controls)

ss = smf.ols(f"inflation_yoy_pct ~ {rhs_ss}", data=df).fit(cov_type="HAC", cov_kwds={"maxlags":12})

beta2_iv = ss.params.get("uxA_hat", np.nan)
se2_iv   = ss.bse.get("uxA_hat", np.nan)
t2_iv    = ss.tvalues.get("uxA_hat", np.nan)
p2_iv    = ss.pvalues.get("uxA_hat", np.nan)

tbl_iv = pd.DataFrame({
    "Metric": ["First-stage F (ai_lag12 → ai)", "β2^IV (u_gap × ÂI)", "Std. Error", "t-stat", "p-value"],
    "Value":  [F_first_stage, beta2_iv,          se2_iv,              t2_iv,       p2_iv]
})
tbl_iv.to_csv(f"{OUTDIR}/table_S6_1_IV_lag12_2SPS.csv", index=False)

# ------------------------
# 3) Placebo: permute AI over time (keep u_gap, π, controls fixed), HAC(12)
# ------------------------
rng = np.random.default_rng(20250919)  # fixed seed for reproducibility
ai_perm = df["ai_share_c"].to_numpy().copy()
rng.shuffle(ai_perm)
df["ai_perm_c"]   = ai_perm
df["uxA_placebo"] = df["u_gap_c"] * df["ai_perm_c"]

pl_rhs = "u_gap_c + uxA_placebo + inflation_yoy_pct_lag1 + inflation_yoy_pct_lag12"
if opt_controls: pl_rhs += " + " + " + ".join(opt_controls)

pl = smf.ols(f"inflation_yoy_pct ~ {pl_rhs}", data=df).fit(cov_type="HAC", cov_kwds={"maxlags":12})

tbl_pl = pd.DataFrame({
    "Parameter":  ["β2 (u_gap × AI_perm)"],
    "Estimate":   [pl.params.get("uxA_placebo", np.nan)],
    "Std. Error": [pl.bse.get("uxA_placebo", np.nan)],
    "t-stat":     [pl.tvalues.get("uxA_placebo", np.nan)],
    "p-value":    [pl.pvalues.get("uxA_placebo", np.nan)]
})
tbl_pl.to_csv(f"{OUTDIR}/table_S6_2_placebo_time_permutation.csv", index=False)

print("Saved:")
print(f"{OUTDIR}/table_S6_1_IV_lag12_2SPS.csv")
print(f"{OUTDIR}/table_S6_2_placebo_time_permutation.csv")
